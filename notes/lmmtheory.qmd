# 선형혼합모형의 이론  {#sec-lmmtheory} 

::: {.callout-note title="고정효과와 임의효과의 표기"}
고정효과는 보통 모형식에서 그릭 문자($\alpha$, $\beta$)로 표시하고 임의효과는 모형식에서 영어 알파벳 문자($a$, $b$)로 표시한다
:::


## 독립군집 모형 

선형혼합모형을 적용할 수 있는 자료의 종류와 구조는 다양하지만 가장 흔하게 나타나는 자료 구조는 독립 군집(independent cluster)의 형태로  $n$ 개의 독립적인 군집(개체, 그룹 등)들에서 각각 $m_i$ 개의 반응값이 나타나는 구조이다.

독립적인 군집은 여러 개의 내포되는 층으로 구성될 수 도 있고(예를 들어 학교, 교사, 학생) 개체(반복측정자료) 또는 공간적/시간적인 군집으로도 나타날 수 있다.  이렇게 독립적 군집에 대한 자료를 설명하는 혼합모형을 **독립군집 모형(indpendent cluster model)** 이라고 부른다.

앞의 @sec-randomcoef 에서 논의한 임의계수모형은 회귀계수에 임의효과가 더해진 독립군집 혼합모형의 특수한 경우로 볼 수 있다. 

예를 들어 @exm-sleep 에서 살펴본 트럭 운전사 자료에서 트럭 운전사는 하나의 군집이 되고 각 운전사마다 반복한 측정치가 있는 자료가 대표적인 예이다. 또한 학교(군집)를 독립적으로 추출하고 각 학교에서 다시 학생들을 추출하는 경우도 독립 군집의 형태라고 할 수 있다.

### 하나의 군집에 대한 모형


먼저 자료가 $n$ 개의 독립적인 군집으로 나누어진 경우를 생각해 보자. 먼저 $i$ 번째 군집에서 측정된 $m_i$ 개의 반응값을 모아 놓은 반응벡터를 $\pmb y_i$ 라고 하고 

$$
\pmb y_i=
\begin{bmatrix}
y_{i1} \\
y_{i2} \\
\vdots\\
y_{i m_i}
\end{bmatrix}
$$

다음과 같은 독립군집 모형을 따른다고 가정한다.

$$
\pmb y_i = \pmb X_i \pmb \beta + \pmb Z_i \pmb b_i + \pmb e_i, \quad i=1,2,\dots,n
$$ {#eq-lmm-indcluster-1}

- $\pmb y_i$ : 반응벡터 $\pmb y_i$ 는 $m_i \times 1$ 벡터로 $i$ 번째 군집에 속한 관측값들을 모아 놓은 벡터이다. 
- $\pmb X_i$: 차원이 $m_i \times p$ 인 행렬로 $i$ 번째 군집의 고정 효과에 대한 계획행렬이다. 
- $\pmb\beta$: $p \times 1$ 의 모수벡터로서 고정 효과를 나타낸다.
- $\pmb Z_i$: 차원이 $m_i \times q$ 인 행렬  $i$ 번째 군집의 임의 효과에 대한 계획행렬이다. 
- $\pmb b_i$: $i$ 번째 군집에 대한 $q$ 개의 임의효과를 모아 놓은 벡터로 $q \times 1$ 차원  벡터이다.
- $\pmb e_i$: $m_i$ 개의 오차를 모아놓은 오차 벡터이다.


또한 군집에 대한 임의효과 벡터와 오차항 벡터의 분포는 각각 다음과 같이 주어진다. 


$$
{\pmb b}_i \sim N(\pmb 0, \pmb G ),\quad {\pmb e}_i \sim N(0, \sigma_e^2 \pmb I), ~~i=1,2,\dots, n
$$ {#eq-lmm-cov-model}  

개체에 대한 임의효과 벡터 $\pmb b_i$ 는 서로 독립적으로 평균이 0 공분산이  $\pmb G$ 인 다변량 정규분포를 따른다. 임의효과의 공분산 행렬 $\pmb G$ 는 양반정치 행렬(semi-positive definite matrix)이다. 여기서 양반정치행렬이라는 의미는 분산의 0이 될 수 있는 양정치 행렬을 말한다.


 모든 오차항은 서로 독립이고 분산은 $\sigma_e^2$ 으로 동일하다.

$$
V(e_{ik}) = \sigma_e^2 \quad \text{ for all } i,k
$$

$$
Cov(e_{ik}, e_{jl}) =0 \text{ for all } i,j,k,l 
$$

다른 개체에 대한 임의효과 벡터는 서로 독립이며 임의 효과 벡터와 오차항 벡터도 독립이다. 

$$  
Cov(\pmb b_{i}, \pmb b_{j}) =\pmb 0 \text{ when } i \ne j
$$

$$
Cov(\pmb a_{i}, \pmb e_{i}) =\pmb 0
$$

::: {#exm-lmm-oneway}


일원배치모형  @eq-re-onewayrandom 은 

$$ y_{ij} = \mu + a_i + e_{ij}, \quad i=1,2,\dots,I,~~ j=1,2,\dots,J $$


독립군집 모형의 가장 단순한 구조로서 $I$ 개의 군집으로 이루어져 있으며 각 군집에서 $J$개의 관측값이 나타난 형태이다. 주어진 그룹 $i$에 대하여 모형을 다음과 같이 행렬식으로 표시한다면 

$$  
\pmb y_i = \pmb X_i \pmb \beta + \pmb Z_i \pmb b_i + \pmb e_i , \quad i=1,2,\dots,I
$$ 

위의 식에서 나타난 각 항은 다음과 같다.

$$  
\pmb y_i=\begin{bmatrix}
y_{i1} \\
y_{i2} \\
\vdots \\
y_{iJ}
\end{bmatrix},~\pmb X_i =
\begin{bmatrix}
1  \\
1  \\
\vdots  \\
1  
\end{bmatrix}, \pmb  \beta=
\begin{bmatrix}
\mu \\
\end{bmatrix}, ~\pmb Z_i =
\begin{bmatrix}
1  \\
1  \\
\vdots  \\
1  
\end{bmatrix},~ \pmb b_i =
\begin{bmatrix}
a_{i} \\
\end{bmatrix},~
\pmb  e_i= 
\begin{bmatrix}
e_{i1} \\
e_{i2} \\
\vdots \\
e_{iJ}
\end{bmatrix}
$$  
:::


::: {#exm-lmm-sleep}

@exm-sleep 에서 살펴본 트럭 운전사 자료에서 임의계수 모형 @eq-re-repeat 을 
다음과 같이 나타낼 수 있다.

$$ 
\begin{aligned}
y_{ij} & = (\beta_0 + b_{0i}) + (\beta_1 + b_{1i}) t_j + e_{ij} \\
 & = (\beta_0  + \beta_1 t_j ) +( b_{0i} +  b_{1i} t_j) + e_{ij} 
\end{aligned}
$$  

위의 임의계수 모형을 독립군집 모형 @eq-lmm-indcluster-1 의 형태로 기술하면 계획행렬 $\pmb X_i$ 와 $\pmb Z_i$ 는 다음과 같다. 

$$  
\pmb y=\begin{bmatrix}
y_{i1} \\
y_{i2} \\
\vdots \\
y_{i,10}
\end{bmatrix},~\pmb X_i =
\begin{bmatrix}
1 & 0 \\
1 & 1 \\
\vdots & \vdots  \\
1 & 9 
\end{bmatrix}, \pmb  \beta=
\begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\end{bmatrix}, ~\pmb Z_i =
\begin{bmatrix}
1 & 0 \\
1 & 1 \\
\vdots & \vdots  \\
1 & 9 
\end{bmatrix},~ \pmb b_i =
\begin{bmatrix}
b_{0i} \\
b_{1i} \\
\end{bmatrix},~
\pmb  e_i= 
\begin{bmatrix}
e_{i1} \\
e_{i2} \\
\vdots \\
e_{i,10}
\end{bmatrix}
$$ 
위의 모형에서 고정효과에 대한 계획행렬 $\pmb X_i$ 와 임의효과에 대한 계획행렬$\pmb Z_i$ 이 같은 것에 유의하자.

:::

### 전체 군집에 대한 모형

위의  각 그룹 $i$ 에 대한 혼합효과모형 @eq-lmm-indcluster-1 을 모두 합쳐서 아래와 같은 행렬식으로 표현할 수 있다.  

$$  
\pmb y =\pmb X \pmb \beta + \pmb  Z \pmb b + \pmb  e 
$$ {#eq-lmm-lme1} 



$$  
\pmb y= \begin{bmatrix}
\pmb y_{1} \\
\pmb y_{2} \\
\vdots \\
\pmb y_{n}
\end{bmatrix}
, \quad
\pmb  X=
\begin{bmatrix}
\pmb X_1 \\
\pmb X_2 \\
\vdots   \\
\pmb  X_{n} 
\end{bmatrix}
, \quad
\pmb  \beta = \pmb \beta 
, \quad
\pmb Z=
\begin{bmatrix}
\pmb Z_1 & \pmb 0 & \dots & \pmb 0 \\
\pmb 0   & \pmb Z_2 & \dots & \pmb 0 \\
\vdots & \vdots & \vdots & \vdots  \\
\pmb 0 & \pmb 0 & \dots & \pmb Z_{I}
\end{bmatrix}
, \quad
\pmb b = 
\begin{bmatrix}
\pmb b_1 \\
\pmb b_2 \\
\vdots \\
\pmb b_n
\end{bmatrix} 
, \quad
\pmb e=
\begin{bmatrix} 
\pmb e_1 \\
\pmb e_2 \\
\vdots  \\
\pmb e_{n} 
\end{bmatrix}
$$  
여기서 반응변수 벡터 $\pmb y$ 와 고정효과 $\pmb \beta$ 에 대한 계획행렬 $\pmb X$ 는 각 군집의 반응변수 벡터 $\pmb y_i$ 와 ${\pmb X}_i$ 를 행으로 쌓아놓은 것으로 표현된다. 오차항에 대한 벡터 $\pmb e$ 도 동일한 형식의 벡터이다.

임의효과 벡터 ${\pmb  b}$ 는 각 군집에 대한 임의효과 벡터 $\pmb b_i$ 를 행으로 쌓아놓은 것과 같고 임의효과에 대한 계획행렬 $\pmb Z$ 는 각 군집의 계획행렬 ${\pmb Z}_i$ 를 대각원소로 구성하는 행렬이다.

다음은 모형 @eq-lmm-lme1 에 나타난 벡터와 행렬의 차원이다. 이 경우 전체 반응변수의 수를 $N$ 이라고 하자.

$$ 
N = m_1 + m_2 + \dots + m_n = \sum_{i=1}^n m_i
$$


- $\pmb y$ : $N \times 1$ 
- $\pmb X$ : $N \times p$
- $\pmb \beta$: $p \times 1$
- $\pmb Z$ : $N \times qn$ 
- $\pmb a$ : $qn \times 1$ 로 나타낸다.
- $\pmb e$ : $N \times 1$

여기서 유의할 점은 군집의개수 $n$ 이 증가해도 고정효과를 나타내는 회귀계수의 벡터 $\pmb \beta$ 의 차원은 변하지 않지만 임의효과에 대한 벡터  $\pmb b$ 의 차원은 증가한다는 사실이다.

또한 임의효과에 대한 계획행렬 $\pmb Z$ 는 원소에 0 이 많은 희소행렬(sparse matrix)로 나타난다. 

임의효과 벡터 $\pmb b$는 $n$개의 임의효과 벡터를 가지는 세로로 쌓은 벡터이고  평균은 $\pmb 0$ 이다. 또한 서로 다른 군집에 대한 임의효과 벡터는 서로 독립이므로 임의효과 벡터 $\pmb b$ 의 공분산 행렬은 차원이 $nq \times nq$ 인 다음과 같은 행렬로  나타난다.


$$  
Cov(\pmb b) =
\begin{bmatrix}
\pmb G & \pmb 0 & \dots & \pmb 0 \\
\pmb 0   & \pmb G & \dots & \pmb 0 \\
\vdots & \vdots & \vdots & \vdots  \\
\pmb 0 & \pmb 0 & \dots & \pmb G
\end{bmatrix}
$$

오차항의 벡터 $\pmb e$는 일반적인 선형모형과 같이 평균이 0 이고 분산이 $\sigma_e^2 \pmb I$인 다변량정규분포를 따른다고 가정한다.

$$   \pmb e \sim N(\pmb 0, \sigma^2_e \pmb I_{N}) $$ 



::: {#exm-lmm-oneway-2}

@exm-lmm-oneway 에서 살펴본 일원배치모형 @eq-re-onewayrandom 을 전체 군집에 대한 혼합모형 @eq-lmm-lme1 의 형태로 나타내면 다음과 같다.


$$  
\pmb y= 
\begin{bmatrix}
y_{11} \\
y_{12} \\
\vdots \\
y_{1J} \\  
y_{21} \\
y_{22} \\
\vdots \\
y_{2J} \\  
\vdots \\  
y_{I1} \\
y_{I2} \\
\vdots \\ 
y_{IJ} \\
\end{bmatrix} 
, \quad
\pmb  X=
\begin{bmatrix}
1 \\
1 \\
\vdots \\
1 \\  
1 \\
1 \\
\vdots \\
1 \\  
\vdots \\  
1 \\
1 \\
\vdots \\
1 \\
\end{bmatrix} 
, \quad
\pmb  \beta = 
\begin{bmatrix}
\mu \\
\end{bmatrix} 
, \quad
\pmb Z=
\begin{bmatrix}
1      & 0      & \dots & 0      \\
1      & 0      & \dots & 0      \\
\vdots & \vdots & \dots & \vdots \\
1      & 0      & \dots & 0      \\  
0      & 1      & \dots & 0      \\
0      & 1      & \dots & 0      \\
\vdots & \vdots & \dots & \vdots \\
0      & 1      & \dots & 0      \\  
\vdots & \vdots & \dots & \vdots \\  
0      & 0      & \dots & 1      \\
0      & 0      & \dots & 1      \\
\vdots & \vdots & \dots & \vdots \\
0      & 0      & \dots & 1      \\
\end{bmatrix} 
, \quad
\pmb b = 
\begin{bmatrix}
a_1 \\
a_2 \\
\vdots \\
a_I
\end{bmatrix} 
, \quad
\pmb e=
\begin{bmatrix} 
e_{11} \\
e_{12} \\
\vdots \\
e_{1J} \\  
e_{21} \\
e_{22} \\
\vdots \\
e_{2J} \\  
\vdots \\  
e_{I1} \\
e_{I2} \\
\vdots \\ 
e_{IJ} \\
\end{bmatrix} 
$$  

임의효과 벡터 $\pmb b$ 는 $I$개의 그룹에 대한 임의효과를 가지는 벡터로서 공분산행렬 $\pmb G$ 는  다음과 같다.

$$
\pmb G = Cov(\pmb b) =
\begin{bmatrix}
\sigma^2_a & 0 & \dots & 0 \\
0   & \sigma^2_a & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots  \\
0 & 0 & \dots & \sigma^2_a
\end{bmatrix}
=  \sigma^2_b \pmb I_{I}
$$

따라서 임의효과 벡터   $\pmb b$ 는 다음과 같은 다변량 정규분포를 따른다.

$$  \pmb b \sim N(\pmb 0, \sigma^2_a \pmb I_{I}) $$ 



오차항의 벡터는 일반적인 선형모형과 같이 평균이 0 이고 분산이 $\sigma_e^2 \pmb I$인 다변량정규분포를 따른다.

$$\pmb e \sim N(\pmb 0, \sigma^2_e \pmb I_{IJ}) $$ 

:::




## 반응값의 분포

이제 선형혼합모형 @eq-lmm-lme1 에서 관측값의 분포에 대하여 살펴보자. 먼저 반응변수 벡터 $\pmb y$ 는 다변량 정규분포를 따르며 기대값 $\pmb \mu$ 과 공분산 행렬 $\pmb V$ 는 다음과 같이 주어진다. 

$$
\begin{aligned}
\pmb \mu & = E(\pmb y)   \\
  & = E(\pmb X \pmb \beta + \pmb Z  \pmb b + \pmb e)  \\
  & = E(\pmb X \pmb \beta) + \pmb Z  E(\pmb b) + E(\pmb e)  \\
  & = \pmb X \pmb \beta + \pmb 0 + \pmb 0  \\
  & = \pmb X \pmb \beta  \\
\pmb V & = Cov (\pmb y)   \\
 & = Cov (\pmb X \pmb \beta + \pmb Z  \pmb b + \pmb e)   \\
 & = Cov (\pmb Z  \pmb b + \pmb e)   \\
 & = Cov (\pmb Z  \pmb b) +  Cov (\pmb e)   \\
 & = \pmb Z Cov(\pmb b) {\pmb Z}^t +  \sigma^2 \pmb I   \\
 & = \pmb  Z  \pmb G {\pmb Z}^t +  \sigma^2 \pmb I  \\ 
\end{aligned}
$$



::: {#exm-lmm-oneway-3}

일원배치모형에서 층(그룹)의 수가 3개이고($I=3$) 각 층에서 관측치가 2개($J=2$)인 경우 
독립군집 모형 @eq-lmm-indcluster-1 에서 각 항은 다음과 같다. 

$$  
\pmb y_i=\begin{bmatrix}
y_{i1} \\
y_{i2} \\
\end{bmatrix},~
\pmb X_i =
\begin{bmatrix}
1  \\
1  \\
\end{bmatrix},~
\pmb  \beta=
\begin{bmatrix}
\mu \\
\end{bmatrix}, ~
\pmb Z_i =
\begin{bmatrix}
1  \\
1  \\
\end{bmatrix},~ 
\pmb b_i =
\begin{bmatrix}
a_{i} \\
\end{bmatrix},~
\pmb  e_i= 
\begin{bmatrix}
e_{i1} \\
e_{i2} \\
\end{bmatrix}
$$  
3개의 그룹을 합친 전체 모형 @eq-lmm-lme1 에서 각 항은 다음과 같다.


또한  각 개체에 대한 임의효과에 대한 계획행렬 $\pmb Z_i$와 전체 계획행렬 $\pmb Z$는 다음과 같이 나타나고 

$$  
\pmb y=\begin{bmatrix}
y_{11} \\
y_{12} \\
y_{21} \\
y_{22} \\
y_{31} \\
y_{32} \\
\end{bmatrix},~
\pmb X =
\begin{bmatrix}
1  \\
1  \\
1  \\
1  \\
1  \\
1  \\
\end{bmatrix},~
\pmb Z =
\begin{bmatrix}
\pmb Z_1 & \pmb 0 & \pmb 0 \\
\pmb 0 & \pmb Z_2 & \pmb 0 \\
\pmb 0 & \pmb 0 & \pmb Z_3 \\
\end{bmatrix} =
\begin{bmatrix}
1 & 0 & 0 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & 0 & 1 \\
\end{bmatrix}, ~
\pmb b=
\begin{bmatrix}
a_{1} \\
a_{2} \\
a_{3}
\end{bmatrix}
$$ 
임의효과 $\pmb b$ 의 공분산 행렬 $\pmb G$이 다음과 같다. 

$$ 
\pmb G = Cov(\pmb b) =  
\begin{bmatrix}
\sigma^2_b & 0 & 0 \\
0 & \sigma^2_b & 0 \\
 0 & 0 & \sigma^2_b
\end{bmatrix}
$$ 


이제 반응 벡터 $\pmb y$ 의 공분산 행렬 $\pmb V = \pmb  Z  \pmb G {\pmb Z}^t +  \sigma^2 \pmb I$ 를 구해보자.

먼저 $\pmb Z \pmb \Sigma \pmb Z^t$은 다음과 같이 나타난다. 

$$
\begin{aligned}
\pmb Z \pmb G \pmb Z^t &= 
\begin{bmatrix}
1 & 0 & 0 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & 0 & 1 \\
\end{bmatrix}
\begin{bmatrix}
\sigma^2_b & 0 & 0 \\
0 & \sigma^2_b & 0 \\
 0 & 0 & \sigma^2_b
\end{bmatrix}
\begin{bmatrix}
1 & 1 & 0  & 0 & 0 & 0 \\
0 & 0 & 1  & 1 & 0 & 0 \\
0 & 0 & 0  & 0 & 1 & 1 \\
\end{bmatrix} \\
& =
\begin{bmatrix}
\sigma^2_b  & \sigma^2_b  & 0 & 0 & 0 & 0\\
\sigma^2_b & \sigma^2_b   & 0 & 0 & 0 & 0\\
 0 & 0 &\sigma^2_b & \sigma^2_b &  0 & 0\\
 0 & 0 &\sigma^2_b & \sigma^2_b &  0 & 0\\
 0 & 0 & 0 & 0 & \sigma^2_b & \sigma^2_b  \\
 0 & 0 & 0 & 0 & \sigma^2_b & \sigma^2_b \\
\end{bmatrix}
\end{aligned}
$$

반응값 벡터  $\pmb y$ 의 공분산 행렬 $\pmb V=\pmb Z \pmb G \pmb Z^t + \sigma^2_e \pmb I$는 다음과 같이 주어진다.

$$  
Cov (\pmb y) = \pmb V =
\begin{bmatrix}
\sigma^2_b +\sigma^2_e & \sigma^2_b  & 0 & 0 & 0 & 0\\
\sigma^2_b & \sigma^2_b+\sigma^2_e   & 0 & 0 & 0 & 0\\
 0 & 0 &\sigma^2_b +\sigma^2_e& \sigma^2_b &  0 & 0\\
 0 & 0 &\sigma^2_b & \sigma^2_b +\sigma^2_e&  0 & 0\\
 0 & 0 & 0 & 0 & \sigma^2_b +\sigma^2_e& \sigma^2_b  \\
 0 & 0 & 0 & 0 & \sigma^2_b & \sigma^2_b+\sigma^2_e  \\
\end{bmatrix}
$$ 
 
같은 그룹에 속한 관측값의 공분산은 $\sigma^2_b$이고 같은 그룹에 속한 두 개의 관측값들에 대한 상관계수는 다음과 같다.

$$ cor(y_{i1}, y_{i2}) = \frac{\sigma^2_b }{\sigma^2_b+\sigma^2_e } $$ 
   
:::


## 예측 

### 예제: IQ 의 예측 

이 예제는 @searle2009variance 의 7장에 나온 예제입니다.

인간의 지능을 정의하고 측정하려는 노력은 오래된 연구의 주제이다. 인간의 지능을 IQ(Intelligence Quotient)로 수량화하고 이를 측정하기 위한 여러 가지 시험들이 제시되었다. 


먼저 문제를 단순하게 하기 위하여 학생들로 구성된 집단을 고려하고 IQ 가 정규분포를 따른다고 가정하자. 이제 IQ 를 측정하기 위하여 시험을 실시하는데 여러 개의 문항으로 구성된 시험을 보고 평균 성적(score)을 IQ 측정에 사용하기로 한다. 이 경우 각 문항의 점수도 정규분포를 따른다고 가정하자. 

만약 한 명의 학생의 평균 성적이 130 인 경우 이 학생의 진짜 IQ 에 대한  **예측값**은 얼마인가?

이러한 문제는 관측된 정보를 이용하여 관측되지 않는 임의효과를 예측하는 유형의 문제로 볼 수 있으며 많은 연구자들이 이러한 문제의 해법을 주는데 많은 노력을 기울여 왔다.

#### 혼합모형

위의 IQ 문제를 푸는 여러 가지 방법 중 하나는 $i$ 번째 학생의 $j$ 번째 문항에 대한 점수  $y_{ij}$ 를 다음과 같이 같은 혼함효과 모형을 따른다고  가정한다. 

일원배치 모형을 이용하여 학생의 실제 IQ 를 $\mu + a_i$ 로 보고 $J$ 개의 다양한 문항에 대한 관측값 $y_{ij}$ 을 통하여  IQ 를 예측하고자 한다.

$$
y_{ij} = \mu + a_i + e_{ij}, \quad i=1,2,\dots,I \text{ and } j=1,2,\dots, J
$$

위의 모형에서 $\mu$는 전체 모집단에 대한 IQ 의 평균으로 생각하면 되고 
임의효과 $a_i$ 는 $i$ 번쨰 학생의 지적 능력과 관련된 효과로 생각할 수 있다.

따라서 $\mu + a_i$를 $i$ 번째 학생의 지적 능력 IQ 로 생각할 수 있다.

여기서 평균 성적 $a_i$는  서로 독립이고 $N(0,\sigma_a^2)$를 따른다고 가정하고 
오차항 $e_{ij}$ 도 서로 독립이며 $N(0,\sigma_e^2)$를 따른다고 가정하자.


#### 평균 점수의 분포

이제 IQ 테스트에서 $i$ 번째 학생의 평균 점수 $\bar y_i$  는 다음과 같이 계산되며

$$ \bar y_i = \frac{\sum_j y_{ij}}{J} = \mu + a_i + \frac{\sum_j e_{ij}}{J}
$$
또한 다음과 같은 통계적 사실과

$$ E(\bar y_i) = E \left (\mu + b_i + \frac{\sum_j e_{ij}}{J} \right )= \mu  $$
$$ 
V(\bar y_i) = V \left (\mu + b_i + \frac{\sum_j e_{ij}}{J} \right )= 
V(b_i)  + V \left (\frac{\sum_j e_{ij}}{J} \right ) = \sigma_b^2 + \frac{\sigma_e^2}{J}
$$

정규분포의 성질에 의하여 $\bar y_i$ 는 다음과 같은 정규분포를 따르게 된다.

$$ \bar y_i \sim N \left (\mu, \sigma_b^2 + \frac{\sigma_e^2}{J} \right ) $$

#### 성적과 IQ 의 결합 분포

또한 $i$ 번째 학생의 실제 IQ 인 $\mu + a_i$ 의 분포는 다음과 같이 주어진다.

$$
\mu + a_i \sim N \left (\mu, \sigma_a^2 \right )
$$
더 나아가 $i$ 번째 학생의 평균 성적 $\bar y_i$ 와 실제 IQ 인  $\mu+a_i$의 공분산은 다음과 같이 주어진다.

$$
\begin{aligned}
Cov(\bar y_i, \mu + a_i) & = Cov \left (\mu+ a_i + \frac{\sum_j e_{ij}}{J}, \mu + a_i \right ) \\
& = Cov \left (a_i, a_i \right ) = \sigma_a^2
\end{aligned}
$$

위와 같은 결과와 다변량 정규분포의 성질을 이용하면 $i$ 번째 학생의 평균 성적 $\bar y_i$ 와 실제 IQ 인  $\mu+b_i$의 결합분포는 다음과 같이 유도할 수 있다.

$$
\begin{bmatrix}
\text{IQ} \\
\text{test escore}
\end{bmatrix}
=
\begin{bmatrix}
\mu + a_i \\
\bar y_{i}
\end{bmatrix}
\sim 
N \left ( 
\begin{bmatrix}
\mu \\
\mu
\end{bmatrix}
,
\begin{bmatrix}
\sigma_a^2 & \sigma_a^2 \\
\sigma_a^2 & \sigma_a^2 + \sigma_e^2/J
\end{bmatrix}
\right )
$$ {#eq-lmm-iq-cov}


#### IQ 의 최적 예측 

$i$ 번째 학생의 평균 성적 $\bar y_i$ 가 주어진 경우 실제 IQ 인  $\mu+a_i$ 어떻게 예측할 수 있을까?

::: {.callout-important}
통계 이론에 의하면 실제 IQ 인  $\mu+a_i$ 에 대한 **최적 예측값(best prediction)** 은 학생의 평균 성적 $\bar y_i$ 가 주어졌을 때  $\mu+a_i$ 에 대한 조건부 기대값(conditiona expectation)이다.
:::

위에서 주어진 결과 @eq-lmm-iq-cov 에서  이변량 정규분포의 조건부 분포에 대한 성질
@eq-multi-conditional 을 이용하면 $\bar y_i$ 가 주어진 경우  $\mu + a_i$ 의 조건부 기대값은 다음과 같이 주어진다.

$$
E(\mu + a_i | \bar y_i)  = \bar y_i + \frac{\sigma_a^2}{\sigma_a^2 + \sigma_e^2/J} (\bar y_i -\mu)  
$$ {#eq-lmm-iq-pred}

모집단의 IQ 의 평균이 $\mu=100$ 이라고 가정하자. 또한 임의효과와 오차항의 분산이 각각 $10^2$ 와 $\sigma_e^2 = 5^2$ 라고 가정하자. 

$$ \mu = 100, \quad \sigma_b^2 = 10^2, \quad \sigma_e^2 = 10^2$$

이제 10개의 문항으로 이루어진 테스트를 통하여 $i$ 번째 학생의 평균 점수 $\bar y_i$ 가 130 점으로 나타났다고 하자. 

$$ \bar y_i = 130, \quad J =10 $$
학생의 실제 IQ 인 $\mu + a_i$ 의 예측값은 얼마인가?

위의 결과 @eq-lmm-iq-pred 에서 주어진 값들을 대입하면 다음과 같이 주어진다.


$$
\begin{aligned}
\widehat {IQ} & =E(\mu + a_i | \bar y_i = 130) \\
& = \bar y_i + \frac{\sigma_a^2}{\sigma_a^2 + \sigma_e^2/J} (\bar y_i -\mu)   \\
& = 100 + \frac{10^2}{10^2 + 10^2/10} (130 -100) \\
& = 127.27 \\
\end{aligned}
$$

위의 식에서 유도한 것은 정규분포를 가정하고 $\mu + a_i$ 에 대한 조건부 기대값을 구한 것이며 이는  $y_{ij}=130$ 이 주어진 경우 IQ 의 $\mu + a_i$ 에 대한 최적 예측값은 127.27 로 나타난 것이다.


### 임의효과의 예측 

임의효과는 관측할 수 없는 확률변수이지만 관측값이 주어진 경우 임의효과에 대한 기대값으로 그 값을 예측할 수 있다. 임의효과는 모수가 아니라 확률변수이므로 이에 대한 추론을 추정(estimation)이라고 하지 않고 예측(prediction)이라고 한다. 

앞에서 공부한 일원배치모형 @eq-re-onewayrandom 에서 임의효과 $a_i$와 그룹의 평균 $\bar y_{i.}$의 공분산 구해보자.

$$
\begin{aligned}
cov(a_i, \bar y_{i.}) & = cov( a_i, \mu + a_i + \bar e_{i.}) \\
  & = cov(a_i, a_i ) \\
  & =var(a_i) \\
  & = \sigma^2_a
\end{aligned}
$$

임의효과 $a_i$와 그룹의 평균 $\bar y_{i.}$는 각각 다음과 같은 정규분포를 따르므로 

$$  
b_i \sim N(0, \sigma^2_a), \quad \bar y_{i.} \sim N \left ( \mu, \sigma^2_a + \frac{\sigma^2_e}{J} \right ) 
$$ 

임의효과 $a_i$와 그룹의 평균 $\bar y_{i.}$는 다음과 같은 이변량 정규분포를 따른다.

$$  
\begin{bmatrix}
a_i \\
\bar y_{i.}
\end{bmatrix}
\sim 
N \left (
\begin{bmatrix}
0 \\
\mu 
\end{bmatrix}
, ~
\begin{bmatrix}
 \sigma^2_a & \sigma^2_a \\
 \sigma^2_a & \sigma^2_a + \sigma^2_e/J
\end{bmatrix}
\right )
$$ 

따라서  그룹의 평균 $\bar y_{i.}$ 이 주어진 경우 임의효과 $a_i$의 조건부 분포는 정규분포이며  조건부 기대값은 다음과 같이 주어진다 (강의노트에서 @eq-multi-conditional 참조)

$$  
\begin{aligned}
E(a_i | \bar y_{i.}) & = E(a_i) + \frac{cov(a_i, \bar y_{i.})}{var(\bar y_{i.})} ( \bar y_{i.} - \mu) \\
& = 0+ \frac{cov(a_i, \bar y_{i.})}{var(\bar y_{i.})} ( \bar y_{i.} - \mu)  \\
& = \frac{\sigma^2_a}{\sigma^2_a + \sigma^2_e/J } (\bar y_{i.}- \mu)
\end{aligned}
$$ 
위의 식에서 모르는 모수 $\mu$, $\sigma^2_a$, $\sigma^2_e$ 를 최대가능도 추정량으로 대체해주면 임의효과 $a_i$에 대한 예측값을 구할 수 있다. 

$$
\begin{aligned}
 \hat a_i & = \hat E(a_i | \bar y_{i.}) \\
 & = \frac{\hat \sigma^2_a}{\hat \sigma^2_a + \hat \sigma^2_e/J } (\bar y_{i.}- \hat \mu) \\
& =  \frac{\hat \sigma^2_a}{\hat \sigma^2_a + \hat \sigma^2_e/J } (\bar y_{i.}- \bar y_{..})
\end{aligned}
$$ {#eq-lmm-prediction}



이제 임의효과 모형에서 그룹의 평균 $\mu + a_i$ 의 예측값을 유도하면 다음과 같다. 


$$
\begin{aligned}
 \widehat {\mu+a_i} & = \hat \mu + \hat a_i \\
 & =\bar y_{..} +\frac{\hat \sigma^2_a}{\hat \sigma^2_a + \hat \sigma^2_e/J } (\bar y_{i.}- \bar y_{..})
\end{aligned}
$$ 


::: {.callout-note title="고정효과의 그룹 평균 예측"}

위의 @eq-lmm-prediction 을 보면 고정효과를 고려한 일원배치모형 @eq-re-anova 에서 각 그룹의 평균 $\mu+\alpha_i$의 추정식과 차이가 나는 것을 볼 수 있다. 

$$  \widehat {\mu+ \alpha_i} = \bar y_{..} + (\bar y_{i.}- \bar y_{..}) = \bar y_{i.} $$ 
:::

임의효과를 이용하면 그룹의 효과가 고정효과를 이용한 모형보다 절대값이 작게 예측되는 것을 알 수 있다.

$$  \left | \frac{\hat \sigma^2_b}{\hat \sigma^2_b + \hat \sigma^2_e/J } (\bar y_{i.}- \bar y_{..}) \right | 
 \le  \left  | y_{i.}- \bar y_{..} \right | $$ 



두 모형에서 비교하면 임의효과 모형에서 그룹 평균에 대한 예측값이 고정효과 모형에서 보다 전체 평균에 더 가깝게 나타나는 것을 알 수 있다. 이러한 현상을 **전체 평균으로의 축소현상(shrinkage to grand mean)** 이라고 부른다.

예제 @exm-sleep 에서 공부한 반복측정자료 `sleepstudy` 에서 혼합모형을 통해서 얻은 각 개인의 절편과 기울기에 대한 예측값이 개체의 개별적인 회귀직선에서 얻은
절편과 기울기보다  전체평균값 방향으로 축소되는 경향(shrinkage)을 볼 수 있다.

<!---

위의 식 \@ref(eq:lme1-dist-2) 에서 전체 임의효과 벡터 $b$ 의 공분산 행렬 $\Sigma$는 다음과 나타난다. 

$$
Cov(b) = \sigma^2 \Sigma =  \sigma^2  
\begin{bmatrix}
 G & 0 & \dots & 0 \\
0   &  G & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots  \\
0 & 0 & \dots &  G
\end{bmatrix}
$$ 

그리고 $\sigma^2$ 으로 스케일링된 공분산 행렬 $V$는 다음과 같이 주어진다.  

```{=tex}
\begin{equation}
  V = V(\theta) = I + Z \Sigma(\theta) Z^t = I + \sum_{i=1}^n Z_i G(\theta) Z^t_i
(\#eq:inf-varcomppara)  
\end{equation}  
```

--->